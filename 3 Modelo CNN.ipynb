{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajo práctico integrador - Visión por Computadoras II\n",
    "## Carrera de Especialización en Inteligencia Artificial - Cohorte 17\n",
    "### Autores:\n",
    "* Piñero, Juan Cruz \n",
    "* Lloveras, Alejandro\n",
    "* Méndez, Diego Martín"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objetivo del trabajo\n",
    "\n",
    "> Procesar **54305** imágenes de hojas, pertenecientes a **14 especies** de plantas, utilizando modelos de *Computer Vision* para clasificar entre plantas saludables y múltiples enfermedades _**(38 clases en total)**_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicialización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de librerías\n",
    "# Gestión de archivos y utilidades\n",
    "import time\n",
    "\n",
    "# Manipulación y análisis de datos\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Machine Learning\n",
    "import tensorflow as tf\n",
    "\n",
    "# Librerías propias\n",
    "import data_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de datos almacenados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               image_path                                           filename  \\\n",
      "id                                                                             \n",
      "0   Strawberry___healthy/  8f558908-aa1b-4a86-855a-5094c2392e5a___RS_HL 1...   \n",
      "1   Strawberry___healthy/  b8e9ed27-8e37-4214-9206-f8c0ef21cf4d___RS_HL 4...   \n",
      "2   Strawberry___healthy/  abdd34a0-ab02-41e0-95a3-a014ab863ec2___RS_HL 1...   \n",
      "3   Strawberry___healthy/  d1aee44a-b6bb-45b9-b7b6-5d553add8fd1___RS_HL 2...   \n",
      "4   Strawberry___healthy/  3d28c3ea-8419-4e09-addd-211e3828e39f___RS_HL 1...   \n",
      "\n",
      "                   class       group      tag  split  \n",
      "id                                                    \n",
      "0   Strawberry___healthy  Strawberry  healthy  train  \n",
      "1   Strawberry___healthy  Strawberry  healthy   test  \n",
      "2   Strawberry___healthy  Strawberry  healthy  train  \n",
      "3   Strawberry___healthy  Strawberry  healthy  train  \n",
      "4   Strawberry___healthy  Strawberry  healthy  train  \n"
     ]
    }
   ],
   "source": [
    "df_split = data_utils.import_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Se han cargado las variables de configuración desde 'constants.yaml'\n",
      " - ROOT_DIR: /Users/alejandrolloveras/.cache/kagglehub/datasets/abdallahalidev/plantvillage-dataset/versions/3/plantvillage dataset/color\n",
      " - DATASETS_ROOT: /Users/alejandrolloveras/.cache/kagglehub/datasets/abdallahalidev/plantvillage-dataset/\n",
      " - DATASET_PATH: /Users/alejandrolloveras/.cache/kagglehub/datasets/abdallahalidev/plantvillage-dataset/versions/3\n",
      " - SPLITTED_PATH: /Users/alejandrolloveras/.cache/kagglehub/datasets/abdallahalidev/plantvillage-dataset/splitted/\n",
      " - AUG_PATH: /Users/alejandrolloveras/.cache/kagglehub/datasets/abdallahalidev/plantvillage-dataset/augmented/\n"
     ]
    }
   ],
   "source": [
    "ROOT_DIR, DATASETS_ROOT, DATASET_PATH, SPLITTED_PATH, AUG_PATH = data_utils.import_from_yaml()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T20:22:43.479100Z",
     "start_time": "2025-04-13T20:22:43.474845Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train', 'test']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits = df_split['split'].value_counts().index.tolist()\n",
    "splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data laoders setup\n",
    "def load_from_directory(data_folder):\n",
    "    \"\"\"\n",
    "    Carga un dataset de imágenes desde un directorio específico.\n",
    "\n",
    "    Args:\n",
    "        data_folder (str): Ruta al directorio que contiene las imágenes.\n",
    "\n",
    "    Returns:\n",
    "        tf.data.Dataset: Dataset de TensorFlow con las imágenes y etiquetas.\n",
    "    \"\"\"\n",
    "    dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        data_folder,  # Ruta al directorio de datos\n",
    "        labels=\"inferred\",  # Las etiquetas se infieren automáticamente desde los nombres de las carpetas\n",
    "        label_mode=\"categorical\",  # Las etiquetas se codifican como categorías (one-hot encoding)\n",
    "        class_names=None,  # Las clases se detectan automáticamente\n",
    "        color_mode=\"rgb\",  # Las imágenes se cargan en modo RGB\n",
    "        batch_size=128,  # Tamaño de lote para el entrenamiento\n",
    "        image_size=(256, 256),  # Redimensiona las imágenes a 128x128 píxeles\n",
    "        shuffle=True,  # Mezcla las imágenes aleatoriamente\n",
    "        seed=42,  # No se utiliza una semilla específica para la aleatorización\n",
    "        validation_split=None,  # No se realiza una división de validación aquí\n",
    "        subset=None,  # No se especifica un subconjunto (train/validation)\n",
    "        interpolation=\"bilinear\",  # Método de interpolación para redimensionar las imágenes\n",
    "        follow_links=False,  # No sigue enlaces simbólicos\n",
    "        crop_to_aspect_ratio=False  # No recorta las imágenes para ajustar la relación de aspecto\n",
    "    )\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga el dataset de imágenes desde el directorio especificado\n",
    "train_images = \"\"; test_images = \"\"; valid_images = \"\"\n",
    "\n",
    "print(\"Cargando datasets desde el directorio…\\n\")\n",
    "for split in splits:\n",
    "    data_folder = f'{SPLITTED_PATH}{split}/'\n",
    "\n",
    "    # Carga el conjunto de datos desde el directorio especificado\n",
    "    # Utiliza la función de TensorFlow para crear un dataset de imágenes\n",
    "    match split:\n",
    "        case 'train':\n",
    "            print(f\"Cargando dataset de entrenamiento desde:\\n > {data_folder}\")\n",
    "            train_images = load_from_directory(data_folder)\n",
    "        case 'test':\n",
    "            print(f\"Cargando dataset de test desde:\\n > {data_folder}\")\n",
    "            test_images = load_from_directory(data_folder)\n",
    "        case 'valid':\n",
    "            print(f\"Cargando dataset de validación desde:\\n > {data_folder}\")\n",
    "            valid_images = load_from_directory(data_folder)\n",
    "        case _: # En caso de no coincidir con ninguno de los splits\n",
    "            print(f\"⚠️ El split '{split}' no es reconocido. No se cargará ningún dataset.\")\n",
    "            continue # Salta al siguiente split\n",
    "    print(f\"✅ Dataset cargado exitosamente.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificamos que los archivos se hayan cargado correctamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Resumen de los datasets cargados:\")\n",
    "print(f\" - Total de imágenes en el dataset de entrenamiento: {len(train_images)}\")\n",
    "print(f\" - Total de imágenes en el dataset de validación: {len(valid_images)}\")\n",
    "print(f\" - Total de imágenes en el dataset de test: {len(test_images)}\")\n",
    "print(f\"Total de imágenes cargadas: {len(train_images) + len(test_images) + len(valid_images)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Clases detectadas:\")\n",
    "[print(\" -\",clase) for clase in train_images.class_names]\n",
    "print(f\"Total de clases: {len(train_images.class_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T20:22:47.309086Z",
     "start_time": "2025-04-13T20:22:47.306963Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumen de los datasets cargados:\n",
      " - Total de imágenes en el dataset de entrenamiento: 1358\n",
      " - Total de imágenes en el dataset de validación: 0\n",
      " - Total de imágenes en el dataset de test: 340\n",
      "Total de imágenes cargadas: 1698\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Resumen de los datasets cargados:\")\n",
    "print(f\" - Total de imágenes en el dataset de entrenamiento: {len(train_images)}\")\n",
    "print(f\" - Total de imágenes en el dataset de validación: {len(valid_images)}\")\n",
    "print(f\" - Total de imágenes en el dataset de test: {len(test_images)}\")\n",
    "print(f\"Total de imágenes cargadas: {len(train_images) + len(test_images) + len(valid_images)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T20:22:47.357567Z",
     "start_time": "2025-04-13T20:22:47.355245Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clases detectadas:\n",
      " - Apple___Apple_scab\n",
      " - Apple___Black_rot\n",
      " - Apple___Cedar_apple_rust\n",
      " - Apple___healthy\n",
      " - Blueberry___healthy\n",
      " - Cherry_(including_sour)___Powdery_mildew\n",
      " - Cherry_(including_sour)___healthy\n",
      " - Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot\n",
      " - Corn_(maize)___Common_rust_\n",
      " - Corn_(maize)___Northern_Leaf_Blight\n",
      " - Corn_(maize)___healthy\n",
      " - Grape___Black_rot\n",
      " - Grape___Esca_(Black_Measles)\n",
      " - Grape___Leaf_blight_(Isariopsis_Leaf_Spot)\n",
      " - Grape___healthy\n",
      " - Orange___Haunglongbing_(Citrus_greening)\n",
      " - Peach___Bacterial_spot\n",
      " - Peach___healthy\n",
      " - Pepper,_bell___Bacterial_spot\n",
      " - Pepper,_bell___healthy\n",
      " - Potato___Early_blight\n",
      " - Potato___Late_blight\n",
      " - Potato___healthy\n",
      " - Raspberry___healthy\n",
      " - Soybean___healthy\n",
      " - Squash___Powdery_mildew\n",
      " - Strawberry___Leaf_scorch\n",
      " - Strawberry___healthy\n",
      " - Tomato___Bacterial_spot\n",
      " - Tomato___Early_blight\n",
      " - Tomato___Late_blight\n",
      " - Tomato___Leaf_Mold\n",
      " - Tomato___Septoria_leaf_spot\n",
      " - Tomato___Spider_mites Two-spotted_spider_mite\n",
      " - Tomato___Target_Spot\n",
      " - Tomato___Tomato_Yellow_Leaf_Curl_Virus\n",
      " - Tomato___Tomato_mosaic_virus\n",
      " - Tomato___healthy\n",
      "Total de clases: 38\n"
     ]
    }
   ],
   "source": [
    "print(f\"Clases detectadas:\")\n",
    "[print(\" -\",clase) for clase in class_names_train]\n",
    "print(f\"Total de clases: {len(class_names_train)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construcción del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arquitectura del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras import Input\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "# Bloque 1\n",
    "model.add(Input(shape=(256, 256, 3)))\n",
    "model.add(layers.Rescaling(1./255))\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.1))\n",
    "\n",
    "# Bloque 2\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.1))\n",
    "\n",
    "# Bloque 3\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.1))\n",
    "\n",
    "# Bloque 4\n",
    "model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.1))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# Capa densa intermedia\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "# Capa de salida con 38 neuronas y softmax para multiclase\n",
    "model.add(layers.Dense(38, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "# Definimos el callback para guardar el mejor modelo según la métrica elegida\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath='best_model.keras',   # Se generará una carpeta con este nombre\n",
    "    monitor='val_loss',            # Métrica a monitorear ('val_accuracy' es otra opción)\n",
    "    save_best_only=True,           # Guarda solo si hay mejora\n",
    "    save_weights_only=False,       # Guarda la arquitectura + pesos\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Ajusta el modelo a tu criterio\n",
    "with tf.device('/GPU:0'):\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "history = model.fit(\n",
    "    train_images,\n",
    "    validation_data=test_images,\n",
    "    epochs=10,\n",
    "    callbacks=[checkpoint_callback]  # Incorporamos el callback\n",
    ")\n",
    "\n",
    "end_time = time.perf_counter()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Tiempo de entrenamiento: {elapsed_time:.2f} segundos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardando resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recording History in json & pickle\n",
    "import json\n",
    "with open('training_hist.json','w') as f:\n",
    "  json.dump(history.history,f)\n",
    "\n",
    "import pickle\n",
    "with open('training_hist.pkl', 'wb') as f:\n",
    "    pickle.dump(history.history, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gráficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = [i for i in range(1,11)]\n",
    "plt.plot(epochs,history.history['accuracy'],color='red',label='Training Accuracy')\n",
    "plt.plot(epochs,history.history['val_accuracy'],color='blue',label='Validation Accuracy')\n",
    "plt.xlabel('No. of Epochs')\n",
    "plt.title('Visualization of Accuracy Result')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation set Accuracy\n",
    "model = tf.keras.models.load_model('best_model.keras')\n",
    "val_loss, val_acc = model.evaluate(test_images)\n",
    "print('Validation accuracy:', val_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
